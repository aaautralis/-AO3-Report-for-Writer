import json
from collections import Counter, defaultdict
from datetime import datetime
from typing import Any, Dict, List, Optional, Set
import sys
import time

def slow_print(text, delay=0.25):
    print(text)
    time.sleep(delay)

DATA_FILE = "my_ao3_db_2025.json"


def wait_next(part_name: str = ""):
    out("\n" * 5)
    tip = f"\nã€{part_name}ã€"
    out("Enter ä»¥ç»§ç»­")
    try:
        input(tip)
    except KeyboardInterrupt:
        out("\nä¸­æ–­é€€å‡ºã€‚")
        sys.exit(0)


def clear_screen():
    out("\n" * 1)


def load_data() -> Optional[Dict[str, Any]]:
    try:
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        out("âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ fetch_data.py")
        return None


def ask_yes_no(prompt: str, default: str = "n") -> bool:
    default = default.lower()
    hint = "Y/n" if default == "y" else "y/N"
    while True:
        ans = input(f"{prompt} ({hint})ï¼š").strip().lower()
        if not ans:
            ans = default
        if ans in ("y", "yes"):
            return True
        if ans in ("n", "no"):
            return False
        out("è¯·è¾“å…¥ y æˆ– nã€‚")


def parse_date(s: Optional[str]) -> Optional[datetime]:
    if not s:
        return None
    try:
        return datetime.strptime(s, "%Y-%m-%d")
    except Exception:
        return None


def safe_list(x) -> List:
    return x if isinstance(x, list) else []


def normalize_rel_tag(tag: str) -> str:
    if not isinstance(tag, str):
        return ""
    t = tag.strip()
    t = t.replace("ï¼", "/").replace(" ", "")
    return t


output_lines: List[str] = []
def out(text: str = ""):
    slow_print(text)
    output_lines.append(text)



def collect_comment_authors_from_tree(tree: Any) -> List[str]:
    authors: List[str] = []

    def walk(node: Any):
        if isinstance(node, dict):
            v = node.get("user")
            if isinstance(v, str) and v.strip():
                authors.append(v.strip())

            for k in node.values():
                if isinstance(k, (dict, list)):
                    walk(k)

        elif isinstance(node, list):
            for i in node:
                walk(i)

    walk(tree)
    return authors


def title_list_preview(titles: List[str], max_show: int = 3) -> str:
    if not titles:
        return ""
    show = titles[:max_show]
    suffix = f" ç­‰{len(titles)}ç¯‡" if len(titles) > max_show else ""
    return "ã€".join(show) + suffix


def format_titles_multiline(
    titles: List[str], indent: str = "    Â· ", max_lines: int = 6
) -> str:
    titles = [t for t in titles if t]
    titles_sorted = sorted(titles)
    if not titles_sorted:
        return ""

    shown = titles_sorted[:max_lines]
    lines = "\n".join(f"{indent}{t}" for t in shown)
    if len(titles_sorted) > max_lines:
        lines += f"\n{indent}â€¦â€¦ä»¥åŠå¦å¤– {len(titles_sorted) - max_lines} ç¯‡"
    return lines


def split_works(
    works: List[Dict[str, Any]], include_hidden: bool, include_anon: bool
):
    main_works = []
    anon_only = []
    hidden_only = []

    for w in works:
        wt = w.get("work_type")
        if wt == "Unrevealed":
            if include_hidden:
                main_works.append(w)
            else:
                hidden_only.append(w)
        elif wt == "Anonymous":
            if include_anon:
                main_works.append(w)
            else:
                anon_only.append(w)
        else:
            main_works.append(w)

    return main_works, anon_only, hidden_only


def top_work_by(key: str, works: List[Dict[str, Any]]):
    valid = [w for w in works if int(w.get(key, 0) or 0) > 0]
    if not valid:
        return None
    return max(valid, key=lambda w: int(w.get(key, 0) or 0))


def get_hottest_chapter(work: Dict[str, Any], author: str):
    counter = Counter()

    for c in safe_list(work.get("comments_tree")):
        user = c.get("user")
        if not user or user == author:
            continue

        idx = c.get("chapter_index")
        if idx is not None:
            counter[idx] += 1

    if not counter:
        return None

    idx, cnt = counter.most_common(1)[0]
    name = f"Chapter {idx}"
    return name, cnt


def main():
    data = load_data()
    if not data:
        return

    account = data.get("account", {})
    username = account.get("username", "Unknown")
    works = safe_list(data.get("works"))


    anon_works = [w for w in works if w.get("work_type") == "Anonymous"]
    hidden_works = [w for w in works if w.get("work_type") == "Unrevealed"]

    print("=" * 60)
    out(f"ğŸ“Š AO3 å¹´ç»ˆå†™ä½œå›é¡¾ Â· {username}")
    print("=" * 60)

    include_hidden = ask_yes_no("è¦æŠŠã€éšè—ä½œå“ï¼ˆUnrevealedï¼‰ã€‘ä¹Ÿç®—è¿›ä¸»è¦ç»Ÿè®¡å—ï¼Ÿ", default="y")
    include_anon = ask_yes_no("è¦æŠŠã€åŒ¿åä½œå“ï¼ˆAnonymousï¼‰ã€‘ä¹Ÿç®—è¿›ä¸»è¦ç»Ÿè®¡å—ï¼Ÿ", default="y")

    public_works, anon_only, hidden_only = split_works(
        works, include_hidden=include_hidden, include_anon=include_anon
    )

    # finished_public = [w for w in public_works if w.get("status") == "Completed"]
    serial_public = [w for w in public_works if len(safe_list(w.get("chapters_detail"))) > 1]

    total_words = sum(int(w.get("words", 0) or 0) for w in public_works)
    real_words = int(total_words * 10 / 9)
    total_kudos = sum(int(w.get("kudos", 0) or 0) for w in public_works)
    total_hits = sum(int(w.get("hits", 0) or 0) for w in public_works)
    total_comments = sum(int(w.get("comments_count", 0) or 0) for w in public_works)

    total_subs = sum(int(w.get("real_subs", 0) or 0) for w in works)
    total_bookmarks = sum(int(w.get("real_bookmarks", 0) or 0) for w in works)

    first_pub_dates = [parse_date(w.get("first_published")) for w in public_works]
    first_pub_dates = [d for d in first_pub_dates if d]

    span_str = ""
    if first_pub_dates:
        d1, d2 = min(first_pub_dates), max(first_pub_dates)
        span_str = f"ä» {d1.strftime('%Y-%m-%d')} åˆ° {d2.strftime('%Y-%m-%d')}ã€‚"


    

    wait_next("åˆå§‹é€‰é¡¹")
    clear_screen()

    out("\n\nã€è¿™ä¸€å¹´ä½ å†™äº†ä»€ä¹ˆã€‘")
    out(f"è¿™ä¸€å¹´ä½ ç»Ÿè®¡äº† {len(public_works)} ç¯‡ä½œå“ï¼Œæ€»å­—æ•° {total_words:,}ï¼Œ{span_str}")
    out(f"å®ƒä»¬ä¸€å…±æ”¶åˆ°äº† {total_kudos} ä¸ªèµã€{total_comments} æ¡è¯„è®ºã€{total_hits} æ¬¡ç‚¹å‡»ã€‚")
    out(f"æ­¤å¤–ä½ ç´¯è®¡è·å¾— {total_subs} ä¸ªè®¢é˜…ã€{total_bookmarks} ä¸ªä¹¦ç­¾ã€‚")
    out("ï¼ˆpsï¼šstats é‡Œèƒ½çœ‹åˆ°ç§å¯†ä¹¦ç­¾/è®¢é˜…æ•°é‡å“¦ã€‚ï¼‰")
    out("\n>> è¯»è€…ä»¬çˆ±ä½ ï¼")
    out("\n\n** ps: AO3çš„å­—æ•°ç»Ÿè®¡æ²¡æœ‰è®¡å…¥ä¸­æ–‡æ ‡ç‚¹ï¼Œå®é™…å­—æ•°æ¯”è¿™è¿˜å¤šï¼")
    out(f"æŒ‰1/10çš„æ ‡ç‚¹ç¬¦å·è®¡ç®—ï¼Œä½ è¶³è¶³å†™äº† {real_words:,} ä¸ªå­—ï¼")

    wait_next("æœ€äº®çœ¼çš„æ˜¯â€¦â€¦ï¼Ÿ")
    clear_screen()

    out("\n\nã€è¿™ä¸€å¹´æœ€äº®çœ¼çš„ä½œå“ã€‘")

    top_kudos_work = top_work_by("kudos", public_works)
    top_bm_work = top_work_by("real_bookmarks", public_works)
    top_cmt_work = top_work_by("comments_count", public_works)

    if top_kudos_work:
        out(f"\nä½ æ”¶åˆ°æœ€å¤šèµçš„æ˜¯ï¼šã€Š{top_kudos_work.get('title')}ã€‹"
              f"ï¼ˆ{top_kudos_work.get('kudos')} ä¸ªèµï¼‰")
        out("ä½ ç«å•¦ï¼")

    if top_bm_work:
        out(f"\n è¢«æ”¶è—æœ€å¤šçš„æ˜¯ã€Š{top_bm_work.get('title')}ã€‹"
              f"ï¼ˆ{top_bm_work.get('real_bookmarks')} ä¸ªä¹¦ç­¾ï¼‰")
        out("å˜¿å˜¿ï¼Œå¥½åƒä¸åŒï¼")

    if top_cmt_work:
        out(f"\n è¯„è®ºæœ€å¤šçš„æ˜¯ã€Š{top_cmt_work.get('title')}ã€‹"
              f"ï¼ˆ{top_cmt_work.get('comments_count')} æ¡è¯„è®ºï¼‰")
        out("è¿™å¤ªå¹¸ç¦äº†ï¼")

    wait_next("è¿™ä¸€å¹´å†™äº†ä»€ä¹ˆ")
    clear_screen()

    # åç»­æ¨¡å—é€»è¾‘ä¸ä½ åŸæ¥ä¸€è‡´ï¼Œæœªæ”¹æ–‡æ¡ˆ
    # ï¼ˆç¯‡å¹…åŸå› è¿™é‡Œä¸å†é‡å¤è§£é‡Šï¼Œåªæ˜¯ä»£ç ï¼‰

    # â€¦â€¦ã€åç»­æ¨¡å—å®Œæ•´ä¿ç•™ï¼Œé€»è¾‘å·²ä¸ JSON å¯¹é½ã€‘â€¦â€¦
    # æ–°å¢ï¼šåˆ†çº§ï¼ˆratingï¼‰åˆ†æ
    rating_counts = Counter()
    for w in public_works:
        rating_counts[w.get("rating", "Unknown") or "Unknown"] += 1

    if rating_counts:
        out("\n\nã€åˆ†çº§å£å‘³ã€‘")
        explicit_mature = rating_counts.get("Explicit", 0) + rating_counts.get("Mature", 0)
        safe_side = rating_counts.get("General Audiences", 0) + rating_counts.get("Teen And Up Audiences", 0)

        # é¡ºæ‰‹æŠŠåˆ†å¸ƒåˆ—å‡ºæ¥ï¼ˆä¸æŒ¤æˆä¸€å¨ï¼‰
        for r, c in rating_counts.most_common():
            out(f"  - {r}ï¼š{c} ç¯‡")

        # ä¸æå¤ªå¤æ‚ï¼šæŒ‰å æ¯”ç»™ä¸¤ä¸‰ç§è¯æœ¯
        if explicit_mature >= max(1, len(public_works) * 0.5):
            out("Explicit / Mature çš„å­˜åœ¨æ„Ÿç›¸å½“å¼ºï¼\n")
            out("ä½ è¿™ä¸€è·¯åœ¨é«˜é€Ÿå…¬è·¯ç‹‚é£™å•Šï¼\n")
        elif safe_side >= max(1, len(public_works) * 0.6):
            out("ä½ çš„åˆ†çº§å¾ˆæ¸©å’Œï¼Œæ›´åƒæ˜¯åœ¨è®¤çœŸå†™å…³ç³»å’Œæ•…äº‹ã€‚\n")
        else:
            out("ä½ æ€ä¹ˆä»€ä¹ˆéƒ½æ²¾ç‚¹ï¼Œå…¨èƒ½å¤§ç¥æ¥çš„å§ï¼\n")

        

    # æ–°å¢ï¼šCategory åˆ†æ
    category_counts = Counter()
    for w in public_works:
        for c in safe_list(w.get("categories")):
            if isinstance(c, str) and c.strip():
                category_counts[c.strip()] += 1

    
    for k, v in category_counts.most_common():
            out(f"  - {k}ï¼š{v} ç¯‡")
    if category_counts:
        out("ä½ çš„å“å‘³åˆ†å¸ƒï¼š")
        mm = category_counts.get("M/M", 0)
        ff = category_counts.get("F/F", 0)
        fm = category_counts.get("F/M", 0)
        dominant = False
        if mm >= max(1, int(len(public_works) * 0.8)):
            out("å“‡ï¼Œä½ çœŸçš„å¾ˆä¸“æ³¨ç”·åŒã€‚")
            out("\n>> ç”·çš„å’Œç”·çš„99ï¼")
            dominant = True
        if ff >= max(1, int(len(public_works) * 0.8)):
            out("å“‡ï¼Œä½ çœŸçš„å¾ˆä¸“æ³¨å¥³åŒã€‚")
            out("\n>> å¥³çš„å’Œå¥³çš„99ï¼")
            dominant = True
        if fm >= max(1, int(len(public_works) * 0.8)):
            out("å“‡ï¼Œä½ çœŸçš„å¾ˆä¸“æ³¨BG/GBã€‚")
            out("\n>> æ­¤ç”·æ­¤å¥³ä¹ƒå¤©ä½œä¹‹åˆï¼")
            dominant = True
        if not dominant:
            out("\n>> ä½ çš„å£å‘³çœŸå¤šå…ƒï¼é«˜é›…äººå£«ï¼")
        

    # æ¨¡å— 2ï¼šå†™ä½œèŠ‚å¥ï¼ˆæŒ‰ç« èŠ‚å‘å¸ƒæ—¶é—´ï¼‰
    update_dates: List[datetime] = []
    for w in public_works:
        for c in safe_list(w.get("chapters_detail")):
            dt = parse_date(c.get("publish_date"))
            if dt:
                update_dates.append(dt)

    out("\n\nã€ä½ çš„æ›´æ–°èŠ‚å¥ã€‘")
    if not update_dates:
        out("å•Šå“¦ï¼Œå‡ºäº†ç‚¹å°é—®é¢˜â€¦â€¦æ›´æ–°æ—¥æœŸèµ°ä¸¢äº†ã€‚")
    else:
        update_dates.sort()
        month_counts = Counter(d.strftime("%Y-%m") for d in update_dates)
        weekday_counts = Counter(d.weekday() for d in update_dates)
        weekday_map = {0: "å‘¨ä¸€", 1: "å‘¨äºŒ", 2: "å‘¨ä¸‰", 3: "å‘¨å››", 4: "å‘¨äº”", 5: "å‘¨å…­", 6: "å‘¨æ—¥"}

        peak_month, peak_cnt = month_counts.most_common(1)[0]
        peak_day, day_cnt = weekday_counts.most_common(1)[0]
        out(f"ä½ æ›´æ–°æœ€é›†ä¸­çš„æœˆä»½æ˜¯ {peak_month}ï¼Œä¸€å…±æ›´æ–°äº† {peak_cnt} æ¬¡ã€‚")
        out(f"ä½ æœ€å¸¸åœ¨ {weekday_map.get(peak_day, 'æŸä¸€å¤©')} æ›´æ–°ï¼ˆ{day_cnt} æ¬¡ï¼‰ã€‚")

        # æœ€é•¿ç©ºæ¡£ï¼ˆæŒ‰ç« èŠ‚å‘å¸ƒæ—¶é—´è®¡ç®—ï¼‰
        gaps = []
        for i in range(1, len(update_dates)):
            gaps.append((update_dates[i] - update_dates[i - 1]).days)

        if gaps:
            longest_gap = max(gaps)
            out(f"\næŒ‰ç« èŠ‚å‘å¸ƒæ—¶é—´ç®—ï¼Œä½ è¿™ä¸€å¹´æœ€é•¿çš„ä¸€æ¬¡â€œæ²‰é»˜æœŸâ€æ˜¯ {longest_gap} å¤©ã€‚")
            if longest_gap < 30:
                out("ä¿æŒæœˆæ›´å•Šï¼Œè¿™ä¹Ÿå¤ªå‹¤å¿«äº†ï¼å¥³ç¥ï¼")
            else:
                out("å¥³ç¥ä¸è¦èµ°â€¦â€¦æˆ‘ä»¬æƒ³ä½ â€¦â€¦")


    # æ¨¡å— 3ï¼šè¿è½½ä¸â€œè¿è½½ä¸­æ›´æ–°å…¶ä»–ç¯‡ç›®â€
    if serial_public:
        wait_next("è¿è½½æ—¶åˆ»")
        clear_screen()
        out("\n\nã€å½“ä½ åœ¨è¿è½½æ—¶ã€‘")
        for w in serial_public:
            chapters = safe_list(w.get("chapters_detail"))
            start = parse_date(chapters[0].get("publish_date")) if chapters else None
            end = parse_date(chapters[-1].get("publish_date")) if chapters else None
            if not start or not end:
                continue

            span_days = (end - start).days
            avg_speed = span_days / len(chapters) if len(chapters) else 0

            overlapping_titles = []
            for other in public_works:
                if other.get("work_id") == w.get("work_id"):
                    continue
                pub = parse_date(other.get("first_published"))
                if pub and start <= pub <= end:
                    overlapping_titles.append(other.get("title", "ï¼ˆæ— æ ‡é¢˜ï¼‰"))

            # åˆ¤æ–­çŠ¶æ€ï¼Œè°ƒæ•´æªè¾
            status_text = "å®Œç»“" if w.get("status") == "Completed" else "æœ€è¿‘ä¸€æ›´"
            out(f"\nã€Š{w.get('title','ï¼ˆæ— æ ‡é¢˜ï¼‰')}ã€‹ä»å¼€æ›´åˆ°{status_text}å†æ—¶ {span_days} å¤©ï¼Œå¹³å‡çº¦ {avg_speed:.1f} å¤©æ›´æ–°ä¸€ç« ã€‚")
            subs = int(w.get("real_subs", 0) or 0)
            bms = int(w.get("real_bookmarks", 0) or 0)

            if subs or bms:
                out(f"è¿™ç¯‡è¿è½½ç´¯è®¡æ”¶è·äº† {subs} ä¸ªè®¢é˜…ã€{bms} ä¸ªä¹¦ç­¾ã€‚")
            else:
                out("è¿™æ˜¯ä¸€ç¯‡å®‰é™ä½†è¢«è®¤çœŸè¯»å®Œçš„è¿è½½ã€‚")
            hot = get_hottest_chapter(w, username)
            if hot:
                chapter, count = hot
                out(f"å…¶ä¸­è®¨è®ºæœ€çƒ­çƒˆçš„æ˜¯ {chapter}ï¼Œæ”¶è·äº† {count} æ¡è¯„è®ºï¼å™¢è€¶ï¼")


            if overlapping_titles:
                sample = title_list_preview(overlapping_titles, max_show=3)
                out(f"\nè¿è½½æœŸé—´,ä½ è¿˜åŒæ—¶å‘å¸ƒäº† {len(overlapping_titles)} ç¯‡å…¶ä»–ä½œå“ï¼ˆæ¯”å¦‚ {sample}ï¼‰ã€‚")
                out("\n>> çœŸæ˜¯ç²¾åŠ›æ—ºç››å•Šï¼æ•™ç¨‹å“ªé‡Œé¢†ï¼Ÿ")
            else:
                out("\n>> ä½ æ€»æ˜¯ä¸“å¿ƒæ‰‘åœ¨è‡ªå·±çš„è¿è½½å†™ä½œä¸Šï¼Œå¤ªä¼Ÿå¤§äº†ï¼")
                out("è¯»è€…ä»¬éƒ½æ³ªæµæ»¡é¢äº†ï¼")
            wait_next(" >>> ")
            clear_screen()
            

    # # === æ’å…¥ä½ç½®ï¼šåœ¨ top_cmt_work çš„ if å—ä¹‹å ===
    
    # # 1. æ±‡æ€»æ‰€æœ‰å±äºç³»åˆ—çš„ä½œå“
    # series_map = defaultdict(list)
    # for w in public_works:
    #     s_name = w.get("series_name")
    #     if s_name:
    #         series_map[s_name].append(w)

    # if series_map:
    #     wait_next("series")
    #     clear_screen()

    #     out("\n\nã€ä½ çš„ç³»åˆ—å®‡å®™ã€‘")
    #     out(f"è¿™ä¸€å¹´ï¼Œä½ å»ºè®¾äº† {len(series_map)} ä¸ªseriesï¼")
    #     for s_name, s_works in series_map.items():
    #         # æŒ‰ series_part æ’åº (Part 1, Part 2...)
    #         s_works.sort(key=lambda x: x.get("series_part") or "")
    #         titles = [f"ã€Š{w['title']}ã€‹({w.get('series_part', '??')})" for w in s_works]
    #         out(f"\nÂ· ç³»åˆ—ã€Š{s_name}ã€‹ï¼š")
    #         out(f"  åŒ…å« {len(titles)} ç¯‡ä½œå“ï¼š{' ã€ '.join(titles)}")
        
    #     # å¦‚æœ fetch é˜¶æ®µæŠ“åˆ°äº† series_list çš„æ±‡æ€»æ•°æ®
    #     all_series_stats = safe_list(data.get("series_list"))
    #     if all_series_stats:
    #         top_s = max(all_series_stats, key=lambda x: x.get("bookmarks", 0))
    #         out(f"\nåœ¨ä½ çš„æ‰€æœ‰ç³»åˆ—ä¸­ï¼Œæœ€å—ç©ç›®çš„æ˜¯ã€Š{top_s['title']}ã€‹ï¼Œ")
    #         out(f"å®ƒå·²ç´¯è®¡è·å¾—äº† {top_s['bookmarks']} ä¸ªbookmarkï¼å™¢è€¶ï¼")

    # åˆé›†çœŸçš„é€‚åˆç»Ÿè®¡å— è¿˜æ˜¯å…ˆä¸ç»Ÿè®¡äº†è°¢è°¢ï¼
    # out("\n\nã€åˆé›†å°è®°ã€‘")
    # # 2. ç»Ÿè®¡åˆé›†æ”¶å½•æƒ…å†µ
    # all_collections = []
    # for w in public_works:
    #     all_collections.extend(safe_list(w.get("collections_info")))
    
    # if not all_collections:
    #     out("è¿™ä¸€å¹´çš„ä½œå“æš‚æ—¶è¿˜æ²¡æœ‰è¢«æ”¶å½•è¿›ä»»ä½•å…¬å¼€åˆé›†ä¸­ã€‚")
    # else:
    #     col_counts = Counter(all_collections)
    #     out(f"ä½ çš„ä½œå“è¿™ä¸€å¹´å‡ºç°åœ¨äº† {len(col_counts)} ä¸ªä¸åŒçš„åˆé›†ä¸­ã€‚")
    #     out("è¢«æ”¶å½•æ¬¡æ•°æœ€å¤šçš„åˆé›†æ˜¯ï¼š")
    #     for name, count in col_counts.most_common(3):
    #         out(f"  - {name} ({count} æ¬¡)")
    #     out("\n>> è°¢è°¢è¿™äº›åˆé›†ä¸»ï¼ŒæŠŠä½ çš„æ–‡å­—å¦¥å–„çè—ã€‚")


    # æ¨¡å— 4ï¼šäº’åŠ¨å¯†åº¦ï¼ˆè¯„è®º/èµï¼‰â€”â€”ä½ è¦æ±‚ç”¨â€œæ¯ä¸ªèµå¯¹åº”å¤šå°‘è¯„è®ºâ€
    # wait_next(" è®¨è®ºå¯†åº¦ ")
    # clear_screen()
    
    out("\n\nã€è®¨è®ºå¯†åº¦ã€‘")
    
    if total_kudos <= 0:
        out("å•Šå“¦ï¼Œå‡ºäº†ç‚¹å°é—®é¢˜â€¦â€¦è®¨è®ºå¯†åº¦èµ°ä¸¢äº†ã€‚")
    else:
        ratio = total_comments / total_kudos
        out(f"å¹³å‡æ¥çœ‹ï¼Œæ¯èµå¯¹åº” {ratio:.2f} æ¡è¯„è®ºã€‚")
        out(f"å¯¹é•¿ç¯‡è¿è½½ï¼Œèµè¯„æ¯”æ¯”kudosæ›´åé¦ˆä½ çš„ä¼˜ç§€å“¦~")
    wait_next("â™ªè°æ˜¯æˆ‘æœ€çˆ±çš„äºº")
    clear_screen()

    # æ¨¡å— 5ï¼šè¯»è€…æ¦œï¼ˆKudos / Commentsï¼‰
    # 5.1 Kudos æ¦œï¼šç»Ÿè®¡â€œç‚¹è¿‡ä½ å¤šå°‘ç¯‡ä½œå“â€
    kudos_user_to_titles: Dict[str, Set[str]] = defaultdict(set)
    for w in works:
        wt = w.get("work_type")

        if wt == "Unrevealed" and not include_hidden:
            continue
        if wt == "Anonymous" and not include_anon:
            continue

        title = w.get("title", "ï¼ˆæ— æ ‡é¢˜ï¼‰")
        for u in safe_list(w.get("kudos_givers")):
            if isinstance(u, str) and u.strip():
                kudos_user_to_titles[u.strip()].add(title)


    # 5.2 Comments æ¦œï¼šä¼˜å…ˆ comments_tree
    comment_user_to_titles: Dict[str, Set[str]] = defaultdict(set)
    for w in works:
        wt = w.get("work_type")

        if wt == "Unrevealed" and not include_hidden:
            continue
        if wt == "Anonymous" and not include_anon:
            continue

        title = w.get("title", "ï¼ˆæ— æ ‡é¢˜ï¼‰")
        tree = w.get("comments_tree")
        authors = collect_comment_authors_from_tree(tree) if tree else []

        for a in authors:
            if a and a not in ("Guest", username):
                comment_user_to_titles[a].add(title)


    out("\n\nã€ç°åœ¨å¼€å§‹æ’­æ”¾ï¼šã€Šçˆ±æˆ‘çš„äºº è°¢è°¢ä½ ã€‹-è–›ä¹‹è°¦ã€‘")
    out("â™ªç™»ç™»ç­‰ç­‰ï¼Œè¯»è€…ä»¬é‡ç£…ç™»åœºï¼")


    wait_next("kudosè‹±é›„æ¦œ")
    clear_screen()


    if kudos_user_to_titles:
        top_kudos = sorted(kudos_user_to_titles.items(), key=lambda x: len(x[1]), reverse=True)[:5]
        out("\nç»™ä½ ç‚¹èµæœ€å¤šçš„äººï¼š")
        for user, titles in top_kudos:
            titles_list = sorted(list(titles))
            out(f"\n- {user}ï¼ˆç•™ä¸‹ {len(titles)} ä¸ªkudosï¼ï¼‰")
            out(format_titles_multiline(titles_list, indent="    Â· ", max_lines=6))
    else:
        out("\nå•Šå“¦ï¼Œå‡ºäº†ç‚¹å°é—®é¢˜â€¦â€¦ç‚¹èµæ¦œæš‚æ—¶æ— æ³•ç”Ÿæˆã€‚")
    
    wait_next("COMMENTè‹±é›„æ¦œ")
    clear_screen()

    if comment_user_to_titles:
        top_comments = sorted(comment_user_to_titles.items(), key=lambda x: len(x[1]), reverse=True)[:5]
        out("\n\næœ€å¸¸åœ¨ä½ è¯„è®ºåŒºå‡ºç°çš„äººï¼š")
        for user, titles in top_comments:
            titles_list = sorted(list(titles))
            out(f"\n- {user}ï¼ˆå¸¦æ¥äº† {len(titles)} ä¸ªå¤§è¯„è®ºï¼ä¹ˆä¹ˆå“’ï¼ï¼‰")
            out(format_titles_multiline(titles_list, indent="    Â· ", max_lines=6))
    else:
        out("\n\nå•Šå“¦ï¼Œå‡ºäº†ç‚¹å°é—®é¢˜â€¦â€¦è¯„è®ºæ¦œæš‚æ—¶æ— æ³•ç”Ÿæˆã€‚")
        out("ï¼ˆæŠ“ä¸åˆ°ï¼Œæ ¹æœ¬æŠ“ä¸åˆ°ï¼æˆ‘çš„ä»£ç åˆå´©æºƒäº†ï¼ï¼‰")
    wait_next("ä½  çš„ ä¸– ç•Œ")
    clear_screen()

    # æ¨¡å— 6ï¼šé¢˜æä¸æ ‡ç­¾å€¾å‘ï¼ˆfandom / relationship / freeformï¼‰
    fandom_counts = Counter()
    rel_counts_raw = Counter()
    rel_counts_norm = Counter()
    freeform_counts = Counter()

    for w in public_works:
        for f in safe_list(w.get("fandoms")):
            if isinstance(f, str) and f.strip():
                fandom_counts[f.strip()] += 1

        for r in safe_list(w.get("relationships")):
            if isinstance(r, str) and r.strip():
                rel_counts_raw[r.strip()] += 1
                rel_counts_norm[normalize_rel_tag(r)] += 1

        for t in safe_list(w.get("freeform_tags")):
            if isinstance(t, str) and t.strip():
                freeform_counts[t.strip()] += 1

    if fandom_counts:
        top_fandom, cnt = fandom_counts.most_common(1)[0]
        out("\n\nã€ä½ å¸¸é©»çš„ä¸–ç•Œã€‘")
        out(f"è¿™ä¸€å¹´ä½ ä¸»è¦å†™çš„æ˜¯ {top_fandom}ï¼ˆå‡ºç°åœ¨ {cnt} ç¯‡ä½œå“é‡Œï¼‰ã€‚")

    if rel_counts_raw:
        out("\n\nã€ä½ å†™çš„å…³ç³»èµ°å‘ã€‘")
        total_rel_tags = sum(rel_counts_raw.values())
        unique_rel_tags = len(rel_counts_raw)

        if unique_rel_tags == total_rel_tags:
            out("ç©å¾—çœŸèŠ±ï¼ä½ å‡ ä¹æ²¡æœ‰å†™è¿‡é‡å¤çš„å…³ç³»/äº§å“ï¼")
        else:
            common = rel_counts_raw.most_common(5)
            out("é•¿æƒ…çš„ä½œè€…å•Šï¼Œä½ æœ€çˆ±åƒè¿™äº›äº§å“ï¼š")
            for r, c in common:
                out(f"  - {r}ï¼ˆ{c} æ¬¡ï¼‰")

        # ä½ è¦çš„è§£é‡Šï¼šå¯èƒ½é‡å¤
        
        out("\nå› ä¸º AO3 çš„ CP/å…³ç³»æ ‡ç­¾å­˜åœ¨åˆ«åã€é¡ºåºå·®å¼‚ã€ä¸­è‹±æ··å†™ã€å…¨è§’æ–œæ ç­‰åŸå› ï¼Œ")
        out("åŒä¸€ä¸ªå…³ç³»å¯èƒ½ä¼šå‡ºç°â€œé‡å¤â€çš„æ¡ç›®ï¼Œæ»‘è·ªTAT")

        wait_next(" é«˜é›…å“å‘³ ")
        clear_screen()

    if freeform_counts:
        out("\n\nã€ä½ åçˆ±çš„ä¸»é¢˜ä¸å£å‘³ã€‘")
        if all(c == 1 for c in freeform_counts.values()):
            out("ä½ è¿™ä¸€å¹´çš„ tag å‡ ä¹æ²¡æœ‰é‡å¤ï¼ŒçœŸæ˜¯å¤šç‚¹å¼€èŠ±å•Šï¼æ¯ä¸€ç¯‡éƒ½åœ¨æœæ–°æ–¹å‘ç‹‚å¥”ï¼")
        else:
            repeated = [(t, c) for t, c in freeform_counts.items() if c > 1]
            repeated.sort(key=lambda x: x[1], reverse=True)

            out("ä½ æ˜æ˜¾åå¥½è¿™äº› tagï¼š")
            for t, c in repeated[:8]:
                out(f"  - {t}ï¼ˆ{c} æ¬¡ï¼‰")

            once_only = [t for t, c in freeform_counts.items() if c == 1]
            once_only.sort()
            if once_only:
                sample = title_list_preview(once_only, max_show=3)
                out("\né™¤æ­¤ä¹‹å¤–ï¼Œä½ ä¹Ÿå†™äº†ä¸å°‘åˆ«çš„ä¸»é¢˜ï¼ŒçœŸæ˜¯å¤šç‚¹å¼€èŠ±å•Šï¼")
                out(f"æ¯”å¦‚ï¼š{sample}")
    wait_next("how will you be next ..?")
    clear_screen()

    # ä½ è¦çš„ï¼šå¦‚æœä¸çº³å…¥åŒ¿å/éšè—ï¼Œå•ç‹¬å¼€å°èŠ‚åšåˆ†æ
    if anon_works:
        out("\n\nã€å˜˜ï¼Œå·å·çš„â€¦â€¦ã€‘")
        out(f"ä½ è¿™ä¸€å¹´è¿˜æœ‰ {len(anon_works)} ç¯‡åŒ¿åä½œå“~~")
        titles = [w.get("title", "ï¼ˆæ— æ ‡é¢˜ï¼‰") for w in anon_works]
        out(format_titles_multiline(titles, indent="    Â· ", max_lines=10))

        anon_words = sum(int(w.get("words", 0) or 0) for w in anon_works)
        anon_kudos = sum(int(w.get("kudos", 0) or 0) for w in anon_works)
        anon_hits = sum(int(w.get("hits", 0) or 0) for w in anon_works)
        anon_comments = sum(int(w.get("comments_count", 0) or 0) for w in anon_works)
        out(f"\nåŒ¿åä½œå“åˆè®¡ï¼š{anon_words:,} å­—ï¼Œ{anon_kudos} èµï¼Œ{anon_comments} è¯„è®ºï¼Œ{anon_hits} ç‚¹å‡»ã€‚")
        out(f">> è¾¾æˆæˆå°±ï¼šé¢å…·ä¹‹ä¸‹ï¼Œæ˜¯æ›´ç¾çš„é¢å…·~")

    if hidden_works:
        out("\n\nã€è¢«éšè—çš„â€¦â€¦ã€‘")
        out(f"ä½ è¿™ä¸€å¹´æœ‰ {len(hidden_works)} ç¯‡éšè—ä½œå“~~")
        titles = [w.get("title", "ï¼ˆæ— æ ‡é¢˜ï¼‰") for w in hidden_works]
        out(format_titles_multiline(titles, indent="    Â· ", max_lines=10))

        hidden_words = sum(int(w.get("words", 0) or 0) for w in hidden_works)
        hidden_kudos = sum(int(w.get("kudos", 0) or 0) for w in hidden_works)
        hidden_hits = sum(int(w.get("hits", 0) or 0) for w in hidden_works)
        hidden_comments = sum(int(w.get("comments_count", 0) or 0) for w in hidden_works)
        out(f"\néšè—ä½œå“åˆè®¡ï¼š{hidden_words:,} å­—ï¼Œ{hidden_kudos} èµï¼Œ{hidden_comments} è¯„è®ºï¼Œ{hidden_hits} ç‚¹å‡»ã€‚")
        out(f">> å“ªå¤©æˆ‘ä»¬ä¼šä¸å®ƒä»¬ç›¸è§å‘¢ï¼Ÿ")
        wait_next("how will you be next..?")
    out("\næŠ¥å‘Šç»“æŸï¼Œè°¢è°¢ä½ çš„å­˜åœ¨ã€‚")
    print(f"æœ€åçš„æœ€åâ€¦â€¦")
    save_txt = ask_yes_no("è¦æŠŠè¿™ä»½å¹´ç»ˆæŠ¥å‘Šä¿å­˜æˆ txt æ–‡ä»¶å—ï¼Ÿ", default="y")
    if save_txt:
        filename = f"AO3_Year_Report_{username}.txt"
        with open(filename, "w", encoding="utf-8") as f:
            f.write("\n".join(output_lines))
        print(f"\nå·²ä¿å­˜ä¸ºï¼š{filename}")


    out("\n" + "=" * 60)
    


if __name__ == "__main__":
    main()
